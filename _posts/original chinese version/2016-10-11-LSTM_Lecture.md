---
layout: post
title: LSTM发明人Sepp Hochreiter慕尼黑工大计算机系讲座笔记
description: "LSTM"
tags: [NN, Deep Learning, LSTM]
categories: [Machine Learning, Machine Learning Basic, Deep Learning]
---

Sepp Hochreiter毕业于慕尼黑工业大学，在校时搞出LSTM，现任教于奥地利林茨大学，此番来德是要去奥迪，顺便路过慕尼黑搞个讲座。

首先Hochreiter先夸一番Deep Learning（后简称DL）现在有多火，尤其是他的LSTM用于谷歌语音，还有最近发布的新版谷歌翻译，效果都很好。其次是Deep Learning在计算机视觉和自然语言处理方面成果惊人。此处省略五分钟和各种错误率等等各种性能改善数据。

然后开始说DL的奇妙之处，用视觉方面的人脸识别为例，也就是CNN（卷积神经网络）：

![dl_faces]({{ site.url }}\images\machine_learning\dl_faces.jpg)

<!-- more -->

这个是经常用的例子，输入层是输入像素点，第一层出来一些edge和corner，第二层出来耳朵，鼻子，眼睛等局部结构，最后一层输出完整或部分的脸。

然后举了一个不常见的例子，就是DL用于寻找药物：

第一层出来一些化学基团，比如羟基，羧基等等

第二层出来一个化合物的反应中心（Interaction Center）

第三层出来药效团（pharmacophore），这个东西就具有生物活性了，是我们需要的



**然后讨论Vanishing Gradient Problem**

在反向传播算法中，要计算每一个神经元的梯度并使用链式法则把梯度相乘，相邻的两层之间的误差满足：



$$\sigma^{i-1}=\sigma^i\cdot J^i$$

其中$$\sigma^i$$是第$$i$$层的误差，$$J^i$$是$$i$$层的雅克比矩阵，亦即梯度。那么第一层的误差就是：



$$\sigma^1=\sigma^T \prod_i J_i$$

其中$$T$$是最后一层的层数。同时我们还知道



$$\| J_i\| \leqslant k <1$$ 

所以当$$T$$很大时（深度学习的层数总是很多的）：



$$\| \sigma^1\|=\|\sigma^T \prod_i J_i\|\approx0 $$

那么越靠近第一层，误差越小，训练的时候几乎没办法更新，导致训练不出来。

这是面对深度网络一直以来存在的障碍。解决方法有：

ReLU：参见博文 [NN: one neuron](https://einsteinliu.github.io/machine%20learning/machine%20learning%20basic/NN1/)

LSTM：可以控制梯度的大小

High way nets

Residual nets

老爷子谈到最近他在搞一个Self-Normalization Network，好像是明天会正式公布的一个成果，可用于搭建超大型AI系统，比如家政服务机器人，登陆火星机器人之类的。

**随后开始谈一些案例**

一个是德国的在线购物网站Zalando，zalando希望通过深度学习对网上的时尚博客，图片，文字进行分析，来把握时尚潮流，为顾客推送喜欢的商品。并且要分地区，比如Milan的客户和San Francisco的客户看到的Zalando页面会完全不同，因为他们的时尚品味不同，商品页面要推送当时当地的时尚热点。比如某一张相片得到了很多赞，就要分析为什么人们会赞？然后预测你喜欢的商品。

**LSTM的一个好处是Uniform Credit Assignment**

就是对关键信息，无论这段信息在什么位置，都能赋予相同的得分（重要性）。

比如以下三个句子：

一个**人在跑步**，他穿在红衣服。

一个穿红衣服的**人在跑步**。

一件红衣服穿在一个**跑步的人**身上。

这三句话中相同的信息“人，跑步”都会得到相同的得分。

因为**LSTM能保存记忆，能保存你看到的东西，一个Situation。**

这个特性用于处理视频效果很好，因为很多场景你光看一张图片看不出什么，得通过视频才能看出来。比如一段视频里面有一个骑车的人，挥出左手，示意要左转。

假设视频中$$t_1$$的时候人挥了左手示意左转，$$t_2$$的时候手放下，$$t_3$$的时候开始真正左转。

如果我们只看到了$$t_3$$的图片，我们很难判断出这个骑车的人在向哪个方向骑，但结合之前的记忆，我们知道，他是在向左骑，这个时候LSTM的优势就体现出来了。

最近还有一个热点是Attention，在一个视频中，如果车子重要，那就put more attention，此处没有深入讲。

**视觉的图像分类（标注，caption）问题：**

CNN把一系列图像输入，得到一个Meaning Pool

RNN把一系列图像输入，得到的是Meaning Sequence，每输入一幅图，就会产生一个新的meaning（caption）。

一个Zalando广告作为例子谈机器学习的局限：

![zalando]({{ site.url }}\images\machine_learning\zalando.jpg)

上图中的妹子拿的两双鞋，会被标注为红酒。为什么？因为拿在手里的红色的东西通过对训练库中图片的学习就应该是红酒，而且，训练库中的鞋子一般都是穿在脚上的，那么拿在手里的鞋子就会被赋予一个极小的概率，于是这一可能性被放弃。

所以训练库必须得大，很大很大，故名“大数据”。

哪来这么多数据呢，比如自动驾驶吧，可以搞一个汽车的“Kindergarten”，让他们自己学。

**还有一个问题是图像分类有时候是伪正确。**什么意思？

比如有一个算法，给他一张两个人打乒乓球的图，他很准确的识别出来了乒乓球。

但这张图中乒乓球速度很快，所以相片中球的形状是拉长的形态，居然也被识别出来了。这是不是意味着这个算法很好呢？并不是，这个算法之所以认出了飞行中的球，只不过是因为图片中有乒乓球台。也就是说，在训练集中，我们只给了“乒乓球”这个标注，没有给出乒乓球台。但因为乒乓球和乒乓球台总是一起出现的，所以算法把数据中乒乓球台的内容当做乒乓球了。如果是一个人对着墙打乒乓球，那就识别不了了。

**最后是提问阶段，问题大多很无聊。**

有人问，深度学习网络的中间输出结果我们可以理解吗？

回答：不能，我有一段时间尝试了好几个月想要理解深度学习网络的中间结果，可以理解某一些东西，但大部分都是不能理解的，我们人类还是太蠢。

又有人问，怕不怕人工智能会灭掉人类？

回答：你想太多了，就凭着现在这点简单的方程就想灭掉人类么，差太远了，我们对大脑一无所知。

完，吃完微软谷歌NVIDIA提供的免费披萨，回家。

![Hochreiter]({{ site.url }}\images\machine_learning\Hochreiter.jpg)

